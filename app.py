import streamlit as st
import pandas as pd
import requests
import time

# --- –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(layout="wide", page_title="GrowthLoop Hybrid Pro v3.4")

# --- –ö–õ–Æ–ß–ò API ---
FNS_API_KEY = "8f1364cd9916da3ba62170204442a80566bc5f29"
OFDATA_API_KEY = "4ag8CvRHFhXpwzOz"

# --- –°–ü–†–ê–í–û–ß–ù–ò–ö –†–ï–ì–ò–û–ù–û–í ---
REGIONS = {
    "–í—Å–µ —Ä–µ–≥–∏–æ–Ω—ã": "", "01 - –ê–¥—ã–≥–µ—è": "01", "02 - –ë–∞—à–∫–æ—Ä—Ç–æ—Å—Ç–∞–Ω": "02", "03 - –ë—É—Ä—è—Ç–∏—è": "03", "04 - –ê–ª—Ç–∞–π": "04",
    "05 - –î–∞–≥–µ—Å—Ç–∞–Ω": "05", "06 - –ò–Ω–≥—É—à–µ—Ç–∏—è": "06", "07 - –ö–∞–±–∞—Ä–¥–∏–Ω–æ-–ë–∞–ª–∫–∞—Ä–∏—è": "07", "08 - –ö–∞–ª–º—ã–∫–∏—è": "08",
    "09 - –ö–∞—Ä–∞—á–∞–µ–≤–æ-–ß–µ—Ä–∫–µ—Å–∏—è": "09", "10 - –ö–∞—Ä–µ–ª–∏—è": "10", "11 - –ö–æ–º–∏": "11", "12 - –ú–∞—Ä–∏–π –≠–ª": "12",
    "13 - –ú–æ—Ä–¥–æ–≤–∏—è": "13", "14 - –Ø–∫—É—Ç–∏—è": "14", "15 - –°–µ–≤–µ—Ä–Ω–∞—è –û—Å–µ—Ç–∏—è": "15", "16 - –¢–∞—Ç–∞—Ä—Å—Ç–∞–Ω": "16",
    "17 - –¢—ã–≤–∞": "17", "18 - –£–¥–º—É—Ä—Ç–∏—è": "18", "19 - –•–∞–∫–∞—Å–∏—è": "19", "20 - –ß–µ—á–Ω—è": "20", "21 - –ß—É–≤–∞—à–∏—è": "21",
    "22 - –ê–ª—Ç–∞–π—Å–∫–∏–π –∫—Ä–∞–π": "22", "23 - –ö—Ä–∞—Å–Ω–æ–¥–∞—Ä—Å–∫–∏–π –∫—Ä–∞–π": "23", "24 - –ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫–∏–π –∫—Ä–∞–π": "24",
    "25 - –ü—Ä–∏–º–æ—Ä—Å–∫–∏–π –∫—Ä–∞–π": "25", "26 - –°—Ç–∞–≤—Ä–æ–ø–æ–ª—å—Å–∫–∏–π –∫—Ä–∞–π": "26", "27 - –•–∞–±–∞—Ä–æ–≤—Å–∫–∏–π –∫—Ä–∞–π": "27",
    "28 - –ê–º—É—Ä—Å–∫–∞—è –æ–±–ª.": "28", "29 - –ê—Ä—Ö–∞–Ω–≥–µ–ª—å—Å–∫–∞—è –æ–±–ª.": "29", "30 - –ê—Å—Ç—Ä–∞—Ö–∞–Ω—Å–∫–∞—è –æ–±–ª.": "30",
    "31 - –ë–µ–ª–≥–æ—Ä–æ–¥—Å–∫–∞—è –æ–±–ª.": "31", "32 - –ë—Ä—è–Ω—Å–∫–∞—è –æ–±–ª.": "32", "33 - –í–ª–∞–¥–∏–º–∏—Ä—Å–∫–∞—è –æ–±–ª.": "33",
    "34 - –í–æ–ª–≥–æ–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª.": "34", "35 - –í–æ–ª–æ–≥–æ–¥—Å–∫–∞—è –æ–±–ª.": "35", "36 - –í–æ—Ä–æ–Ω–µ–∂—Å–∫–∞—è –æ–±–ª.": "36",
    "37 - –ò–≤–∞–Ω–æ–≤—Å–∫–∞—è –æ–±–ª.": "37", "38 - –ò—Ä–∫—É—Ç—Å–∫–∞—è –æ–±–ª.": "38", "39 - –ö–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª.": "39",
    "40 - –ö–∞–ª—É–∂—Å–∫–∞—è –æ–±–ª.": "40", "41 - –ö–∞–º—á–∞—Ç—Å–∫–∏–π –∫—Ä–∞–π": "41", "42 - –ö–µ–º–µ—Ä–æ–≤—Å–∫–∞—è –æ–±–ª.": "42",
    "43 - –ö–∏—Ä–æ–≤—Å–∫–∞—è –æ–±–ª.": "43", "44 - –ö–æ—Å—Ç—Ä–æ–º—Å–∫–∞—è –æ–±–ª.": "44", "45 - –ö—É—Ä–≥–∞–Ω—Å–∫–∞—è –æ–±–ª.": "45",
    "46 - –ö—É—Ä—Å–∫–∞—è –æ–±–ª.": "46", "47 - –õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª.": "47", "48 - –õ–∏–ø–µ—Ü–∫–∞—è –æ–±–ª.": "48",
    "49 - –ú–∞–≥–∞–¥–∞–Ω—Å–∫–∞—è –æ–±–ª.": "49", "50 - –ú–æ—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª.": "50", "51 - –ú—É—Ä–º–∞–Ω—Å–∫–∞—è –æ–±–ª.": "51",
    "52 - –ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–∞—è –æ–±–ª.": "52", "53 - –ù–æ–≤–≥–æ—Ä–æ–¥—Å–∫–∞—è –æ–±–ª.": "53", "54 - –ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–∞—è –æ–±–ª.": "54",
    "55 - –û–º—Å–∫–∞—è –æ–±–ª.": "55", "56 - –û—Ä–µ–Ω–±—É—Ä–≥—Å–∫–∞—è –æ–±–ª.": "56", "57 - –û—Ä–ª–æ–≤—Å–∫–∞—è –æ–±–ª.": "57",
    "58 - –ü–µ–Ω–∑–µ–Ω—Å–∫–∞—è –æ–±–ª.": "58", "59 - –ü–µ—Ä–º—Å–∫–∏–π –∫—Ä–∞–π": "59", "60 - –ü—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª.": "60",
    "61 - –†–æ—Å—Ç–æ–≤—Å–∫–∞—è –æ–±–ª.": "61", "62 - –†—è–∑–∞–Ω—Å–∫–∞—è –æ–±–ª.": "62", "63 - –°–∞–º–∞—Ä—Å–∫–∞—è –æ–±–ª.": "63",
    "64 - –°–∞—Ä–∞—Ç–æ–≤—Å–∫–∞—è –æ–±–ª.": "64", "65 - –°–∞—Ö–∞–ª–∏–Ω—Å–∫–∞—è –æ–±–ª.": "65", "66 - –°–≤–µ—Ä–¥–ª–æ–≤—Å–∫–∞—è –æ–±–ª.": "66",
    "67 - –°–º–æ–ª–µ–Ω—Å–∫–∞—è –æ–±–ª.": "67", "68 - –¢–∞–º–±–æ–≤—Å–∫–∞—è –æ–±–ª.": "68", "69 - –¢–≤–µ—Ä—Å–∫–∞—è –æ–±–ª.": "69",
    "70 - –¢–æ–º—Å–∫–∞—è –æ–±–ª.": "70", "71 - –¢—É–ª—å—Å–∫–∞—è –æ–±–ª.": "71", "72 - –¢—é–º–µ–Ω—Å–∫–∞—è –æ–±–ª.": "72",
    "73 - –£–ª—å—è–Ω–æ–≤—Å–∫–∞—è –æ–±–ª.": "73", "74 - –ß–µ–ª—è–±–∏–Ω—Å–∫–∞—è –æ–±–ª.": "74", "75 - –ó–∞–±–∞–π–∫–∞–ª—å—Å–∫–∏–π –∫—Ä–∞–π": "75",
    "76 - –Ø—Ä–æ—Å–ª–∞–≤—Å–∫–∞—è –æ–±–ª.": "76", "77 - –ú–æ—Å–∫–≤–∞": "77", "78 - –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥": "78",
    "79 - –ï–≤—Ä–µ–π—Å–∫–∞—è –ê–û": "79", "82 - –ö—Ä—ã–º": "82", "83 - –ù–µ–Ω–µ—Ü–∫–∏–π –ê–û": "83", "86 - –•–ú–ê–û": "86",
    "87 - –ß—É–∫–æ—Ç—Å–∫–∏–π –ê–û": "87", "89 - –Ø–º–∞–ª–æ-–ù–µ–Ω–µ—Ü–∫–∏–π –ê–û": "89", "92 - –°–µ–≤–∞—Å—Ç–æ–ø–æ–ª—å": "92"
}

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---

def clean_val(val):
    if not val: return ""
    if isinstance(val, list):
        if not val: return ""
        if isinstance(val[0], dict):
            items = []
            for i in val:
                name = i.get('–§–ò–û') or i.get('–ù–∞–∏–º–°–æ–∫—Ä–Æ–õ') or i.get('–ù–∞–∏–º–ù–∞–ª–æ–≥') or i.get('–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ')
                value = i.get('–°—É–º–£–ø–ª–ù–∞–ª') or i.get('–°—É–º–º–∞') or i.get('–î–æ–ª—è–ü—Ä–æ—Ü–µ–Ω—Ç')
                if name and value: items.append(f"{name}: {value}")
                elif name: items.append(str(name))
                elif value: items.append(str(value))
            return " | ".join(items) if items else ""
        return ", ".join(map(str, val))
    if isinstance(val, dict):
        parts = [f"{v}" for k, v in val.items() if v]
        return " | ".join(parts)
    return str(val)

def process_contacts(df, col_name, prefix):
    if col_name not in df.columns: return df
    contacts_series = df[col_name].apply(lambda x: x if isinstance(x, list) else [])
    max_len = contacts_series.map(len).max()
    if pd.isna(max_len) or max_len == 0: return df.drop(columns=[col_name])
    new_cols = pd.DataFrame(contacts_series.tolist(), index=df.index)
    new_cols.columns = [f"{prefix} {i+1}" for i in range(new_cols.shape[1])]
    return pd.concat([df, new_cols], axis=1).drop(columns=[col_name])

def toggle_all_selection():
    if 'results' in st.session_state and st.session_state['results'] is not None:
        st.session_state['results']['–í—ã–±—Ä–∞—Ç—å'] = st.session_state.select_all_cb

# --- –ò–ù–¢–ï–†–§–ï–ô–° –°–ê–ô–î–ë–ê–†–ê ---
st.sidebar.title("üéØ –§–∏–ª—å—Ç—Ä—ã –ø–æ–∏—Å–∫–∞")

okved_input = st.sidebar.text_input("–û–ö–í–≠–î—ã (—á–µ—Ä–µ–∑ | )", placeholder="62 –∏–ª–∏ 62.01|62.02")
sel_region_name = st.sidebar.selectbox("–†–µ–≥–∏–æ–Ω", list(REGIONS.keys()))
region_code = REGIONS[sel_region_name]

st.sidebar.markdown("---")

with st.sidebar.expander("üí∞ –í—ã—Ä—É—á–∫–∞ (–º–ª–Ω —Ä—É–±.)", expanded=True):
    r_col1, r_col2 = st.columns(2)
    with r_col1:
        rev_min = st.number_input("–û—Ç", value=0, key="rev_min", label_visibility="collapsed")
    with r_col2:
        rev_max = st.number_input("–î–æ", value=0, key="rev_max", label_visibility="collapsed")

with st.sidebar.expander("üë• –ü–∞—Ä–∞–º–µ—Ç—Ä—ã"):
    staff_min = st.number_input("–°–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –æ—Ç", value=0)
    with_phone = st.checkbox("–¢–æ–ª—å–∫–æ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–æ–º")
    with_email = st.checkbox("–¢–æ–ª—å–∫–æ —Å Email")
    active_only = st.checkbox("–¢–æ–ª—å–∫–æ –¥–µ–π—Å—Ç–≤—É—é—â–∏–µ", value=True)

# --- –§–£–ù–ö–¶–ò–Ø –ó–ê–ü–†–û–°–ê –ö API –§–ù–° ---
def fetch_fns_data(page=1):
    f_parts = ["onlyul"]
    if active_only: f_parts.append("active")
    if okved_input:
        if "|" in okved_input or "." in okved_input: f_parts.append(f"okved{okved_input}")
        else: f_parts.append(f"okvedgroup{okved_input}")
    if region_code: f_parts.append(f"region{region_code}")
    if rev_min > 0 or rev_max > 0:
        v_str = "vyruchka"
        if rev_min > 0: v_str += f">{rev_min * 1000}"
        if rev_max > 0: v_str += f"<{rev_max * 1000}"
        f_parts.append(v_str)
    if staff_min > 0: f_parts.append(f"sotrudnikov>{staff_min}")
    if with_phone: f_parts.append("withphone")
    if with_email: f_parts.append("withemail")

    filter_final = "+".join(f_parts)
    search_url = f"https://api-fns.ru/api/search?q=any&filter={filter_final}&page={page}&key={FNS_API_KEY}"
    
    try:
        r = requests.get(search_url, timeout=20)
        if r.status_code == 200:
            return r.json().get("items", [])
        elif r.status_code == 403:
            st.error(f"–û—à–∏–±–∫–∞ 403: –î–æ–±–∞–≤—å—Ç–µ IP {r.text} –≤ –õ–ö API.")
            return None
    except Exception as e:
        st.error(f"–°–±–æ–π: {e}")
        return None

# --- –õ–û–ì–ò–ö–ê –ö–ù–û–ü–û–ö –ü–û–ò–°–ö–ê ---
if st.sidebar.button("–ù–∞–π—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏ (–ø–µ—Ä–≤—ã–µ 100)", use_container_width=True):
    # –°–±—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –Ω–æ–≤–æ–º –ø–æ–∏—Å–∫–µ
    st.session_state['current_page'] = 1
    items = fetch_fns_data(page=1)
    if items:
        df = pd.json_normalize(items)
        df.columns = [c.split('.')[-1] for c in df.columns]
        df.insert(0, "–í—ã–±—Ä–∞—Ç—å", False)
        st.session_state['results'] = df
        st.session_state['search_count'] = len(df)
    else:
        st.session_state['results'] = None
        st.warning("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

# --- –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –¢–ê–ë–õ–ò–¶–´ ---
if 'results' in st.session_state and st.session_state['results'] is not None:
    
    st.metric("–ù–∞–π–¥–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π –≤ —Å–ø–∏—Å–∫–µ", st.session_state['search_count'])
    
    st.checkbox("–í—ã–±—Ä–∞—Ç—å –≤—Å–µ", key="select_all_cb", on_change=toggle_all_selection)
    
    # –†–µ–¥–∞–∫—Ç–æ—Ä —Ç–∞–±–ª–∏—Ü—ã
    edited_df = st.data_editor(
        st.session_state['results'], 
        use_container_width=True, 
        hide_index=True,
        column_config={"–í—ã–±—Ä–∞—Ç—å": st.column_config.CheckboxColumn("–í—ã–±—Ä–∞—Ç—å")},
        key="table_editor"
    )

    # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Ä—É—á–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞
    if st.session_state.get("table_editor"):
        for row_idx, edit in st.session_state.table_editor["edited_rows"].items():
            if "–í—ã–±—Ä–∞—Ç—å" in edit:
                st.session_state['results'].iat[int(row_idx), 0] = edit["–í—ã–±—Ä–∞—Ç—å"]

    # –ö–ù–û–ü–ö–ê –î–û–ó–ê–ì–†–£–ó–ö–ò –°–õ–ï–î–£–Æ–©–ò–• 100
    if st.button("üîΩ –ó–∞–≥—Ä—É–∑–∏—Ç—å –µ—â–µ 100 –∫–æ–º–ø–∞–Ω–∏–π", use_container_width=True):
        st.session_state['current_page'] += 1
        new_items = fetch_fns_data(page=st.session_state['current_page'])
        
        if new_items:
            new_df = pd.json_normalize(new_items)
            new_df.columns = [c.split('.')[-1] for c in new_df.columns]
            new_df.insert(0, "–í—ã–±—Ä–∞—Ç—å", st.session_state.select_all_cb) # –ü–æ–¥—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–¥ —á–µ–∫–±–æ–∫—Å "–í—ã–±—Ä–∞—Ç—å –≤—Å–µ"
            
            # –°–∫–ª–µ–∏–≤–∞–µ–º –∏ —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –ò–ù–ù
            combined_df = pd.concat([st.session_state['results'], new_df], ignore_index=True)
            combined_df = combined_df.drop_duplicates(subset=['–ò–ù–ù'], keep='first')
            
            st.session_state['results'] = combined_df
            st.session_state['search_count'] = len(combined_df)
            st.rerun() # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
        else:
            st.info("–ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ —ç—Ç–æ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–µ—Ç.")

    selected = st.session_state['results'][st.session_state['results']["–í—ã–±—Ä–∞—Ç—å"] == True]
    
    # --- –û–ë–û–ì–ê–©–ï–ù–ò–ï ---
    st.markdown("---")
    if st.button(f"üöÄ –û–±–æ–≥–∞—Ç–∏—Ç—å –¥–∞–Ω–Ω—ã–º–∏ ({len(selected)})", use_container_width=True):
        if selected.empty:
            st.warning("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–º–ø–∞–Ω–∏–∏!")
        else:
            enriched = []
            bar = st.progress(0)
            inns = selected['–ò–ù–ù'].tolist()
            
            for i, inn in enumerate(inns):
                try:
                    res = requests.get(f"https://api.ofdata.ru/v2/company?key={OFDATA_API_KEY}&inn={inn}").json()
                    if "data" in res: enriched.append(res["data"])
                    time.sleep(0.15)
                except: pass
                bar.progress((i + 1) / len(inns))
            
            if enriched:
                final_df = pd.json_normalize(enriched)
                final_df = process_contacts(final_df, '–ö–æ–Ω—Ç–∞–∫—Ç—ã.–¢–µ–ª', '–¢–µ–ª–µ—Ñ–æ–Ω')
                final_df = process_contacts(final_df, '–ö–æ–Ω—Ç–∞–∫—Ç—ã.–ï–º—ç–π–ª', 'Email')
                for col in final_df.columns:
                    final_df[col] = final_df[col].apply(clean_val)
                final_df.columns = [c.replace('.', ' ') for c in final_df.columns]
                
                st.subheader("üíé –§–∏–Ω–∞–ª—å–Ω–∞—è –±–∞–∑–∞")
                st.dataframe(final_df, use_container_width=True)
                csv = final_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("üì• –°–∫–∞—á–∞—Ç—å CSV", csv, "leads.csv", "text/csv")
