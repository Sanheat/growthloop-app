import streamlit as st
import pandas as pd
import requests
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(layout="wide", page_title="GrowthLoop Engine - Advanced Search")

API_KEY = "4ag8CvRHFhXpwzOz"
BASE_URL = "https://api.ofdata.ru/v2"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö (—É–±–∏—Ä–∞–µ–º [object Object])
def clean_list_columns(val):
    if isinstance(val, list):
        if not val: return ""
        if isinstance(val[0], str): return ", ".join(val)
        if isinstance(val[0], dict):
            readable_items = []
            for item in val:
                pairs = [f"{k}: {v}" for k, v in item.items() if v is not None]
                readable_items.append(" | ".join(pairs))
            return "; ".join(readable_items)
    return val

# --- –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ (–§–ò–õ–¨–¢–†–´) ---
st.sidebar.title("üéØ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫")

okved_query = st.sidebar.text_input("–ö–æ–¥ –û–ö–í–≠–î", "63.11")
region_code = st.sidebar.text_input("–ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞", "77")

st.sidebar.markdown("---")
st.sidebar.subheader("üí∞ –§–∏–Ω–∞–Ω—Å—ã (–º–ª–Ω —Ä—É–±.)")
# –í–≤–æ–¥–∏–º –≤ –º–∏–ª–ª–∏–æ–Ω–∞—Ö –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞, –≤ API –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∏—Å—Ç—ã–µ —á–∏—Å–ª–∞
rev_min = st.sidebar.number_input("–í—ã—Ä—É—á–∫–∞ –æ—Ç (–º–ª–Ω)", value=0) * 1_000_000
rev_max = st.sidebar.number_input("–í—ã—Ä—É—á–∫–∞ –¥–æ (–º–ª–Ω)", value=0) * 1_000_000

prof_min = st.sidebar.number_input("–ü—Ä–∏–±—ã–ª—å –æ—Ç (–º–ª–Ω)", value=0) * 1_000_000
prof_max = st.sidebar.number_input("–ü—Ä–∏–±—ã–ª—å –¥–æ (–º–ª–Ω)", value=0) * 1_000_000

st.sidebar.subheader("üë• –ö–æ–º–∞–Ω–¥–∞")
staff_min = st.sidebar.number_input("–°–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –æ—Ç", value=0)
staff_max = st.sidebar.number_input("–°–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –¥–æ", value=0)

# --- –õ–û–ì–ò–ö–ê –ü–û–ò–°–ö–ê ---
if st.sidebar.button("–ù–∞–π—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏"):
    search_url = f"{BASE_URL}/search"
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Advanced Search
    params = {
        "key": API_KEY,
        "by": "advanced", # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
        "obj": "org",
        "okved": okved_query,
        "region": region_code,
        "active": "true",
        "limit": 100
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ —É–∫–∞–∑–∞–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
    if rev_min > 0: params["revenue_min"] = rev_min
    if rev_max > 0: params["revenue_max"] = rev_max
    if prof_min > 0: params["profit_min"] = prof_min
    if prof_max > 0: params["profit_max"] = prof_max
    if staff_min > 0: params["staff_min"] = staff_min
    if staff_max > 0: params["staff_max"] = staff_max
    
    with st.spinner('–°–∫–∞–Ω–∏—Ä—É–µ–º —Ä–µ–µ—Å—Ç—Ä—ã –ø–æ –≤–∞—à–∏–º —Ñ–∏–ª—å—Ç—Ä–∞–º...'):
        try:
            response = requests.get(search_url, params=params)
            res_data = response.json()
            if "data" in res_data and "–ó–∞–ø–∏—Å–∏" in res_data["data"]:
                found_list = res_data["data"]["–ó–∞–ø–∏—Å–∏"]
                df = pd.DataFrame(found_list)
                df.insert(0, "–í—ã–±—Ä–∞—Ç—å", False) 
                df = df.rename(columns={"–ù–∞–∏–º–°–æ–∫—Ä": "–ù–∞–∑–≤–∞–Ω–∏–µ", "–ò–ù–ù": "–ò–ù–ù", "–Æ—Ä–ê–¥—Ä–µ—Å": "–ê–¥—Ä–µ—Å"})
                st.session_state['found_companies'] = df
            else:
                st.error("–ü–æ —Ç–∞–∫–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º –∫–æ–º–ø–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")

# --- –ò–ù–¢–ï–†–§–ï–ô–° –í–´–ë–û–†–ê –ò –û–ë–û–ì–ê–©–ï–ù–ò–Ø ---
if 'found_companies' in st.session_state:
    st.subheader("üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞")
    
    edited_df = st.data_editor(
        st.session_state['found_companies'],
        column_config={"–í—ã–±—Ä–∞—Ç—å": st.column_config.CheckboxColumn("–í—ã–±—Ä–∞—Ç—å", default=False)},
        disabled=st.session_state['found_companies'].columns.drop("–í—ã–±—Ä–∞—Ç—å"),
        hide_index=True,
        use_container_width=True
    )

    selected_rows = edited_df[edited_df["–í—ã–±—Ä–∞—Ç—å"] == True]
    st.write(f"‚úÖ –í—ã–±—Ä–∞–Ω–æ –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è: **{len(selected_rows)}**")

    if st.button("üöÄ –û–±–æ–≥–∞—Ç–∏—Ç—å (–°–æ–±—Ä–∞—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ)"):
        if len(selected_rows) == 0:
            st.warning("–û—Ç–º–µ—Ç—å—Ç–µ –∫–æ–º–ø–∞–Ω–∏–∏ –≥–∞–ª–æ—á–∫–∞–º–∏.")
        else:
            all_raw_data = []
            progress = st.progress(0)
            inns = selected_rows['–ò–ù–ù'].tolist()
            
            for i, inn in enumerate(inns):
                try:
                    res = requests.get(f"{BASE_URL}/company", params={"key": API_KEY, "inn": inn}).json()
                    if "data" in res:
                        all_raw_data.append(res["data"])
                except: continue
                progress.progress((i + 1) / len(inns))
                time.sleep(0.1)

            if all_raw_data:
                final_df = pd.json_normalize(all_raw_data)
                for col in final_df.columns:
                    final_df[col] = final_df[col].apply(clean_list_columns)
                
                st.subheader("üíé –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ü–µ–ª—è–º")
                st.dataframe(final_df, use_container_width=True)
                
                csv = final_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("üì• –°–∫–∞—á–∞—Ç—å CSV", csv, "leads_enriched.csv", "text/csv")
